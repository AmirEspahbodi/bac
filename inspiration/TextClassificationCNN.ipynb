{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOfNRKBebk1-",
    "outputId": "ae98bcd0-9952-4d5c-fee6-40e2253b3f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ysS-WeabyGB",
    "outputId": "91b53df8-a908-4951-e084-38c98f682323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata==0.4.1 in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.31.0)\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.8.2)\n",
      "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchdata==0.4.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6hE75u1b3DD",
    "outputId": "3f57a183-231d-4b75-8e7a-1f52406e57b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.13.1 in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (2.31.0)\n",
      "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.12.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchtext==0.13.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "w2LsSBEib4qq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchtext\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zEUfhCyb6gg",
    "outputId": "ada0935a-8a2d-41b9-aa3e-6a193a8cd0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu8s0SfadwGY"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6LM00RMkdwkt"
   },
   "outputs": [],
   "source": [
    "from torchtext import transforms as T\n",
    "\n",
    "VOCAB_FILE = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "\n",
    "tokenizer = T.BERTTokenizer(\n",
    "    vocab_path=VOCAB_FILE, do_lower_case=True, return_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU6vKdpifSPN"
   },
   "source": [
    "## Vocab (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8SnS9JAIfSqo"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "vocab = GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4HWhM9wcDKk"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvmTfKEqb7zm",
    "outputId": "04466f65-bed4-476c-99dd-d7ea9f919b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShardingFilterIterDataPipe, ShardingFilterIterDataPipe)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_set, test_set = datasets.AG_NEWS(\"/content/\", split=(\"train\", \"test\"))\n",
    "train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WAeW_SO7cF8z"
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    labels = torch.LongTensor([b[0] for b in batch]) - 1\n",
    "    text = [b[1] for b in batch]\n",
    "    lines = tokenizer(text)\n",
    "    vecs = [vocab.get_vecs_by_tokens(line) for line in lines]\n",
    "    vecs = pad_sequence(vecs)\n",
    "\n",
    "    return vecs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "3cNV_KNncudn"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(test_set, batch_size=64, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emogIDNicwEV",
    "outputId": "1dbb6ddf-f5ff-430a-8d56-3e4236658475"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([169, 64, 50]),\n",
       " tensor([2, 0, 1, 1, 0, 0, 1, 0, 3, 2, 1, 1, 1, 3, 0, 0, 1, 0, 1, 0, 2, 2, 3, 2,\n",
       "         2, 0, 3, 1, 3, 3, 1, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 0, 3, 1, 1, 2,\n",
       "         0, 0, 1, 1, 1, 0, 1, 3, 0, 3, 3, 2, 1, 0, 3, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLV_s-DLc0-F"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "89B-scFGc1ZI"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbLo1Fjvc4d8"
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4mkb-nsec2qC"
   },
   "outputs": [],
   "source": [
    "num_cls = 4\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbOz3l25dIo9"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Mtryyyk3dI0q"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, embed_dim, filter_sizes, num_filters, num_classes, dropout):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1d_list = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv1d(\n",
    "                    in_channels=embed_dim,\n",
    "                    out_channels=num_filters[i],\n",
    "                    kernel_size=filter_sizes[i],\n",
    "                )\n",
    "                for i in range(len(filter_sizes))\n",
    "            ]\n",
    "        )\n",
    "        self.fc = nn.Linear(sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 2, 0)  # x shape: (batch_size, embedding_dim, max_seq_length)\n",
    "\n",
    "        # Apply convolutional filters\n",
    "        conv_outputs = []\n",
    "        for conv in self.conv1d_list:\n",
    "            conv_output = conv(\n",
    "                x\n",
    "            )  # conv_output shape: (batch_size, num_filters, conv_seq_length)\n",
    "            conv_output = F.relu(conv_output)\n",
    "            conv_output = F.max_pool1d(conv_output, conv_output.size(2)).squeeze(\n",
    "                2\n",
    "            )  # conv_output shape: (batch_size, num_filters)\n",
    "            conv_outputs.append(conv_output)\n",
    "\n",
    "        x = torch.cat(\n",
    "            conv_outputs, 1\n",
    "        )  # x shape: (batch_size, num_filters * len(filter_sizes))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)  # logits shape: (batch_size, num_classes)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwWqBoJjjsPq"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "C9iF9QMvjsta"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None):\n",
    "    model.train()\n",
    "    loss_train = AverageMeter()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for inputs, targets in tepoch:\n",
    "            if epoch is not None:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train.update(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            tepoch.set_postfix(loss=loss_train.avg, accuracy=100 * correct / total)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return model, loss_train.avg, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "1mAmKDE6juI0"
   },
   "outputs": [],
   "source": [
    "def validation(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    loss_valid = AverageMeter()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            loss_valid.update(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return loss_valid.avg, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7qjqbIvkHC1"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa3_4mTHkLDc"
   },
   "source": [
    "### Step 1: check forward path\n",
    "\n",
    "Calculate loss for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyGe3-hkkGYm",
    "outputId": "03cd5c90-e20e-42a9-b572-c7d5c18a85b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 64, 50]) torch.Size([64])\n",
      "tensor(1.6286, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(\n",
    "    embed_dim=50,\n",
    "    filter_sizes=[3, 4, 5],\n",
    "    num_filters=[100, 100, 100],\n",
    "    num_classes=num_cls,\n",
    "    dropout=0.5,\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(x_batch.shape, y_batch.shape)\n",
    "outputs = model(x_batch.to(device))\n",
    "loss = loss_fn(outputs, y_batch.to(device))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAi-uA7bkls5"
   },
   "source": [
    "### Step 2: select best lr\n",
    "\n",
    "Train all data for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EGQigywkl08",
    "outputId": "9802baf5-277b-4a78-9d4f-55f54c9ea578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR=0.1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [03:54,  7.99batch/s, accuracy=79.3, loss=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.01\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [03:57,  7.89batch/s, accuracy=85.4, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [03:59,  7.84batch/s, accuracy=75.9, loss=0.648]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.0001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [03:59,  7.83batch/s, accuracy=44.3, loss=1.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    print(f\"LR={lr}\")\n",
    "    model = CNNModel(\n",
    "        embed_dim=50,\n",
    "        filter_sizes=[3, 4, 5],\n",
    "        num_filters=[100, 100, 100],\n",
    "        num_classes=num_cls,\n",
    "        dropout=0.5,\n",
    "    ).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4, momentum=0.9)\n",
    "    for epoch in range(num_epochs):\n",
    "        model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq1d4hyynYvl"
   },
   "source": [
    "### Step 3: train more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "K1RLFZz2nTsM"
   },
   "outputs": [],
   "source": [
    "model = CNNModel(\n",
    "    embed_dim=50,\n",
    "    filter_sizes=[3, 4, 5],\n",
    "    num_filters=[100, 100, 100],\n",
    "    num_classes=num_cls,\n",
    "    dropout=0.5,\n",
    ").to(device)\n",
    "\n",
    "lr = 0.01\n",
    "wd = 1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "\n",
    "acc_train_hist = []\n",
    "acc_valid_hist = []\n",
    "\n",
    "best_loss_valid = torch.inf\n",
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnboOih5nfdS",
    "outputId": "924b9020-7228-4781-9d83-9246454e2250"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [03:54,  8.01batch/s, accuracy=85.5, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.331, Acc = 89.22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 1875batch [04:03,  7.69batch/s, accuracy=88.7, loss=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.331, Acc = 89.21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 1875batch [04:08,  7.55batch/s, accuracy=89.4, loss=0.309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.3025, Acc = 89.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 1875batch [03:55,  7.96batch/s, accuracy=89.8, loss=0.296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.2945, Acc = 90.29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 1875batch [03:57,  7.89batch/s, accuracy=90.1, loss=0.285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.2942, Acc = 90.16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 1875batch [03:55,  7.96batch/s, accuracy=90.5, loss=0.278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.3281, Acc = 88.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 1875batch [03:56,  7.92batch/s, accuracy=90.7, loss=0.271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2986, Acc = 90.32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 1875batch [03:58,  7.88batch/s, accuracy=90.9, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.2847, Acc = 90.64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 1875batch [03:56,  7.92batch/s, accuracy=90.9, loss=0.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2853, Acc = 90.8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 1875batch [03:56,  7.92batch/s, accuracy=91.1, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.2789, Acc = 90.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: : 1875batch [03:53,  8.03batch/s, accuracy=91.3, loss=0.251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2802, Acc = 91.09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: : 1875batch [03:56,  7.94batch/s, accuracy=91.4, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2845, Acc = 90.82\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: : 1875batch [03:57,  7.89batch/s, accuracy=91.5, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2912, Acc = 90.64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: : 1875batch [03:59,  7.82batch/s, accuracy=91.6, loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2837, Acc = 90.79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: : 1875batch [03:57,  7.91batch/s, accuracy=91.6, loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.2808, Acc = 90.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model, loss_train, acc_train = train_one_epoch(\n",
    "        model, train_loader, loss_fn, optimizer, epoch\n",
    "    )\n",
    "    # Validation\n",
    "    loss_valid, acc_valid = validation(model, test_loader, loss_fn)\n",
    "\n",
    "    loss_train_hist.append(loss_train)\n",
    "    loss_valid_hist.append(loss_valid)\n",
    "\n",
    "    acc_train_hist.append(acc_train)\n",
    "    acc_valid_hist.append(acc_valid)\n",
    "\n",
    "    if loss_valid < best_loss_valid:\n",
    "        torch.save(model, f\"model.pt\")\n",
    "        best_loss_valid = loss_valid\n",
    "        print(\"Model Saved!\")\n",
    "\n",
    "    print(f\"Valid: Loss = {loss_valid:.4}, Acc = {acc_valid:.4}\")\n",
    "    print()\n",
    "\n",
    "    epoch_counter += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}