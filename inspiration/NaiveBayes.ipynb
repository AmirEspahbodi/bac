{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5728, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"emails.csv\")\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "1141  Subject: 5000 full color postcards for $ 329  ...      1\n",
      "3129  Subject: re : price processes for ng  grant & ...      0\n",
      "785   Subject: any med for your girl to be happy !  ...      1\n",
      "2599  Subject: great divide lodge  vince and shirley...      0\n",
      "4529  Subject: earth day - trash bash  i hardly know...      0\n",
      "3138  Subject: risk boston  please read the attached...      0\n",
      "550   Subject: renew your vitality  for the first ti...      1\n",
      "5171  Subject: the garp 2001 convention : gentle rem...      0\n",
      "328   Subject: just to her . . .  your message to tj...      1\n",
      "1250  Subject: re :  good day ,  everybody will love...      1\n"
     ]
    }
   ],
   "source": [
    "random_samples = dataset.sample(10)\n",
    "print(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Percentage = 23.88268156424581 %\n",
      "Ham Percentage = 76.11731843575419 %\n"
     ]
    }
   ],
   "source": [
    "spam = dataset[dataset[\"label\"] == 1]\n",
    "ham = dataset[dataset[\"label\"] == 0]\n",
    "print(\"Spam Percentage =\", (len(spam) / len(dataset)) * 100, \"%\")\n",
    "print(\"Ham Percentage =\", (len(ham) / len(dataset)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 4009\n",
      "Test data size: 1719\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"text\"], dataset[\"label\"], test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Checking the sizes of train and test sets\n",
    "print(\"Train data size:\", train_data.shape[0])\n",
    "print(\"Test data size:\", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'subject volatility curves  linked from reuters  hi tanya   attached are the live reuters  linked volatility curves  please don  t  re  establish links  as i don  t think that your telerate connection works in  the same way as ours in london  i will get back to you on cleaning up the  historical forward curve database as i complete each metal  we can talk at  5 pm as we agreed   regards   anjam  p  s  i think the fast dial is  830 5383 or 830 35383'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import re\n",
    "\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Preprocess train emails\n",
    "preprocessed_train_emails = [preprocess_text(text) for text in train_data]\n",
    "\n",
    "# Preprocess test emails\n",
    "preprocessed_test_emails = [preprocess_text(text) for text in test_data]\n",
    "\n",
    "preprocessed_train_emails[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Building the Vocabulary\n",
    "vocabulary = set()\n",
    "for email in preprocessed_train_emails:\n",
    "    words = word_tokenize(email)  # Tokenization using NLTK\n",
    "    vocabulary.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count= 4009\n",
      "prior_spam= 0.23122973310052383\n",
      "prior_ham= 0.7687702668994761\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Calculating Prior Probabilities\n",
    "spam_count = sum(1 for label in train_labels if label == 1)\n",
    "ham_count = sum(1 for label in train_labels if label == 0)\n",
    "total_count = len(train_labels)\n",
    "\n",
    "prior_spam = spam_count / total_count\n",
    "prior_ham = ham_count / total_count\n",
    "print(\"total_count=\", total_count)\n",
    "print(\"prior_spam=\", prior_spam)\n",
    "print(\"prior_ham=\", prior_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "FreqDist({'_': 9365, 'the': 6466, 'to': 5614, 'and': 4645, 'of': 4022, 'you': 3394, 'a': 3257, 'in': 2787, 'your': 2534, 'for': 2216, ...})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Calculating Conditional Probabilities\n",
    "spam_word_counts = FreqDist()\n",
    "ham_word_counts = FreqDist()\n",
    "\n",
    "for email, label in zip(preprocessed_train_emails, train_labels):\n",
    "    words = word_tokenize(email)\n",
    "    if label == 1:\n",
    "        spam_word_counts.update(words)\n",
    "    else:\n",
    "        ham_word_counts.update(words)\n",
    "\n",
    "spam_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# Step 5: Implementing the Naive Bayes Classifier\n",
    "def calculate_conditional_probabilities(word_counts):\n",
    "    # Calculate conditional probabilities with Laplace smoothing\n",
    "    probabilities = {}\n",
    "    vocab_size = len(vocabulary)\n",
    "    total_count = sum(word_counts.values())\n",
    "\n",
    "    for word in vocabulary:\n",
    "        count = word_counts[word]\n",
    "        probability = (count + 1) / (total_count + vocab_size)\n",
    "        probabilities[word] = probability\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "spam_word_probs = calculate_conditional_probabilities(spam_word_counts)\n",
    "ham_word_probs = calculate_conditional_probabilities(ham_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(email):\n",
    "    words = word_tokenize(preprocess_text(email))\n",
    "    log_prob_spam = math.log(prior_spam)\n",
    "    log_prob_ham = math.log(prior_ham)\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            log_prob_spam += math.log(spam_word_probs[word])\n",
    "            log_prob_ham += math.log(ham_word_probs[word])\n",
    "\n",
    "    return 1 if log_prob_spam > log_prob_ham else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987783595113438\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Predict labels for test emails\n",
    "predicted_labels = [predict(email) for email in preprocessed_test_emails]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(\n",
    "    1 for predicted, actual in zip(predicted_labels, test_labels) if predicted == actual\n",
    ")\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}