{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOfNRKBebk1-",
    "outputId": "222d98fc-3796-431a-ca1d-d41c2f6cb5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ysS-WeabyGB",
    "outputId": "9f966f97-d9b9-435f-81fa-bd68f79c242f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchdata==0.4.1\n",
      "  Downloading torchdata-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.4.1) (2.31.0)\n",
      "Collecting portalocker>=2.0.0 (from torchdata==0.4.1)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting torch==1.12.1 (from torchdata==0.4.1)\n",
      "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchdata==0.4.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.4.1) (2023.7.22)\n",
      "Installing collected packages: torch, portalocker, torchdata\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "  Attempting uninstall: torchdata\n",
      "    Found existing installation: torchdata 0.7.0\n",
      "    Uninstalling torchdata-0.7.0:\n",
      "      Successfully uninstalled torchdata-0.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
      "torchtext 0.16.0 requires torchdata==0.7.0, but you have torchdata 0.4.1 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed portalocker-2.8.2 torch-1.12.1 torchdata-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6hE75u1b3DD",
    "outputId": "f164d616-9108-45ce-bf9e-c73b01e84346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.13.1\n",
      "  Downloading torchtext-0.13.1-cp310-cp310-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (2.31.0)\n",
      "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.12.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.13.1) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1->torchtext==0.13.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.13.1) (2023.7.22)\n",
      "Installing collected packages: torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.16.0\n",
      "    Uninstalling torchtext-0.16.0:\n",
      "      Successfully uninstalled torchtext-0.16.0\n",
      "Successfully installed torchtext-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w2LsSBEib4qq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchtext\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zEUfhCyb6gg",
    "outputId": "39635fa0-bae8-4918-9484-64de1094b6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu8s0SfadwGY"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LM00RMkdwkt",
    "outputId": "cc362cbb-d516-457e-b508-8ad9eb4b74b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232k/232k [00:00<00:00, 6.61MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext import transforms as T\n",
    "\n",
    "VOCAB_FILE = \"https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\"\n",
    "\n",
    "tokenizer = T.BERTTokenizer(\n",
    "    vocab_path=VOCAB_FILE, do_lower_case=True, return_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU6vKdpifSPN"
   },
   "source": [
    "## Vocab (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SnS9JAIfSqo",
    "outputId": "3f96cf9d-1640-47ab-bf37-d8aacbce2c6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:07<00:00, 56773.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "vocab = GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4HWhM9wcDKk"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvmTfKEqb7zm",
    "outputId": "6dc18c2f-8ac3-44f7-9576-fa88049cc5f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShardingFilterIterDataPipe, ShardingFilterIterDataPipe)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_set, test_set = datasets.AG_NEWS(\"/content/\", split=(\"train\", \"test\"))\n",
    "train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WAeW_SO7cF8z"
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    labels = torch.LongTensor([b[0] for b in batch]) - 1\n",
    "    text = [b[1] for b in batch]\n",
    "    lines = tokenizer(text)\n",
    "    vecs = [vocab.get_vecs_by_tokens(line) for line in lines]\n",
    "    vecs = pad_sequence(vecs)\n",
    "    return vecs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3cNV_KNncudn"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(test_set, batch_size=64, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emogIDNicwEV",
    "outputId": "d6f76b6f-2d66-45b5-ebf4-147ded692d25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([199, 64, 50]),\n",
       " tensor([3, 2, 1, 0, 3, 1, 2, 2, 3, 2, 0, 3, 2, 3, 3, 3, 2, 3, 3, 1, 3, 0, 2, 2,\n",
       "         3, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 0, 3, 1, 1, 3, 0, 2, 0, 0, 0, 3, 0, 2,\n",
       "         0, 0, 3, 1, 1, 3, 0, 3, 2, 3, 0, 0, 2, 3, 0, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLV_s-DLc0-F"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "89B-scFGc1ZI"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbLo1Fjvc4d8"
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4mkb-nsec2qC"
   },
   "outputs": [],
   "source": [
    "num_cls = 4\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbOz3l25dIo9"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Mtryyyk3dI0q"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, RNN, input_size, hidden_size, num_layers, bidirectional, num_cls\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rnn = RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=False,\n",
    "        )\n",
    "        self.fc = nn.LazyLinear(\n",
    "            num_cls\n",
    "        )  # automatically infers the input size the first time it sees data\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, _ = self.rnn(\n",
    "            x\n",
    "        )  # outputs:hidden states for each time step. _:final hidden state (ignored)\n",
    "        out = outputs.mean(dim=0)\n",
    "        y = self.fc(out)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwWqBoJjjsPq"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "C9iF9QMvjsta"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None):\n",
    "    model.train()\n",
    "    loss_train = AverageMeter()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for inputs, targets in tepoch:\n",
    "            if epoch is not None:\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train.update(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            tepoch.set_postfix(loss=loss_train.avg, accuracy=100 * correct / total)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return model, loss_train.avg, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1mAmKDE6juI0"
   },
   "outputs": [],
   "source": [
    "def validation(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    loss_valid = AverageMeter()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            loss_valid.update(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return loss_valid.avg, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7qjqbIvkHC1"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa3_4mTHkLDc"
   },
   "source": [
    "### Step 1: check forward path\n",
    "\n",
    "Calculate loss for one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyGe3-hkkGYm",
    "outputId": "4325563a-c8e8-4fc4-99fd-e1db060f420a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3810, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:248: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(nn.RNN, 50, 64, 1, False, num_cls).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "outputs = model(x_batch.to(device))\n",
    "loss = loss_fn(outputs, y_batch.to(device))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAi-uA7bkls5"
   },
   "source": [
    "### Step 2: select best lr\n",
    "\n",
    "Train all data for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EGQigywkl08",
    "outputId": "2d595cf6-dcf9-4ba9-d219-a8dae44ef7c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [01:30, 20.62batch/s, accuracy=47.4, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [01:30, 20.61batch/s, accuracy=70, loss=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [01:31, 20.55batch/s, accuracy=47.9, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [01:30, 20.70batch/s, accuracy=26.7, loss=1.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    print(f\"LR={lr}\")\n",
    "    model = RNNModel(nn.RNN, 50, 64, 1, False, num_cls).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4, momentum=0.9)\n",
    "    for epoch in range(num_epochs):\n",
    "        model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq1d4hyynYvl"
   },
   "source": [
    "### Step 3: train more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "K1RLFZz2nTsM"
   },
   "outputs": [],
   "source": [
    "model = RNNModel(nn.RNN, 50, 64, 1, False, num_cls).to(device)\n",
    "\n",
    "lr = 0.01\n",
    "wd = 1e-4\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_train_hist = []\n",
    "loss_valid_hist = []\n",
    "\n",
    "acc_train_hist = []\n",
    "acc_valid_hist = []\n",
    "\n",
    "best_loss_valid = torch.inf\n",
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnboOih5nfdS",
    "outputId": "9f6cd4de-919b-4c75-d8b4-4c8d25aae7d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1875batch [01:33, 20.15batch/s, accuracy=73, loss=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.5004, Acc = 83.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 1875batch [01:29, 20.85batch/s, accuracy=86.1, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.4389, Acc = 85.78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 1875batch [01:30, 20.81batch/s, accuracy=86.6, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4505, Acc = 85.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: : 1875batch [01:30, 20.68batch/s, accuracy=87.2, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.4041, Acc = 87.33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: : 1875batch [01:30, 20.83batch/s, accuracy=87.5, loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.3936, Acc = 87.22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: : 1875batch [01:30, 20.74batch/s, accuracy=86.3, loss=0.424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4545, Acc = 85.32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: : 1875batch [01:30, 20.79batch/s, accuracy=83.7, loss=0.508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4496, Acc = 85.62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: : 1875batch [01:31, 20.44batch/s, accuracy=86.3, loss=0.419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4129, Acc = 86.68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: : 1875batch [01:30, 20.74batch/s, accuracy=87.1, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4153, Acc = 85.74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: : 1875batch [01:30, 20.73batch/s, accuracy=87.3, loss=0.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4454, Acc = 85.93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: : 1875batch [01:32, 20.37batch/s, accuracy=87.6, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n",
      "Valid: Loss = 0.3875, Acc = 87.33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: : 1875batch [01:30, 20.74batch/s, accuracy=84.8, loss=0.462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4343, Acc = 86.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: : 1875batch [01:31, 20.49batch/s, accuracy=86.7, loss=0.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4232, Acc = 86.88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: : 1875batch [01:30, 20.80batch/s, accuracy=87.4, loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.3903, Acc = 87.74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: : 1875batch [01:31, 20.41batch/s, accuracy=87.7, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: Loss = 0.4104, Acc = 87.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model, loss_train, acc_train = train_one_epoch(\n",
    "        model, train_loader, loss_fn, optimizer, epoch\n",
    "    )\n",
    "    # Validation\n",
    "    loss_valid, acc_valid = validation(model, test_loader, loss_fn)\n",
    "\n",
    "    loss_train_hist.append(loss_train)\n",
    "    loss_valid_hist.append(loss_valid)\n",
    "\n",
    "    acc_train_hist.append(acc_train)\n",
    "    acc_valid_hist.append(acc_valid)\n",
    "\n",
    "    if loss_valid < best_loss_valid:\n",
    "        torch.save(model, f\"model.pt\")\n",
    "        best_loss_valid = loss_valid\n",
    "        print(\"Model Saved!\")\n",
    "\n",
    "    print(f\"Valid: Loss = {loss_valid:.4}, Acc = {acc_valid:.4}\")\n",
    "    print()\n",
    "\n",
    "    epoch_counter += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}